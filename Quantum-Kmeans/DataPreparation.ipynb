{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and preprocessing of the EuroSAT data\n",
    "This Jupyter Notebook will present an example of how to prepare and preprocess an image dataset. The EuroSAT satellite images are used as an example, because they will be needed in the quantum K-means implementation in the Jupyter Notebook called \"QKmeans\". \n",
    "\n",
    "The steps executed in this notebook will be the following:\n",
    "1. Transforming the image dataset into a CSV file\n",
    "\n",
    "2. Reading the images and performing feature extraction with VGG16\n",
    "\n",
    "3. Reducing the dimensions of the dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with importing all the necessary libraries\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transforming the image dataset into a csv file\n",
    "The first step will be getting the information of the image paths and their labels into a CSV file. To do this step, the EuroSAT dataset should be downloaded on your computer, it can be downloaded from https://zenodo.org/records/7711810#.ZAm3k-zMKEA . In this example we are using the RGB version of the dataset, which contains jpg images, but there is also a mutli-spectral verison available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to the directory where the data is stored\n",
    "root_dir = '/Path/to/your/EuroSAT_RGB'\n",
    "#root_dir2 = '/Users/mmakital/Document/EuroSAT_MS' # the other version of the dataset, RGB is easier to handle so we use that\n",
    "\n",
    "# Initializing the lists which will contain the paths to te images and their labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# We loop over each subdirectory in the root directory to save every image\n",
    "for class_label in os.listdir(root_dir):\n",
    "    class_dir = os.path.join(root_dir, class_label)\n",
    "\n",
    "    if os.path.isdir(class_dir): #check to see if it is a directory\n",
    "        # loop over the images in that directory and save them into the lists\n",
    "        for image_file in os.listdir(class_dir):\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_paths.append(os.path.join(class_dir, image_file))\n",
    "                labels.append(class_label)\n",
    "\n",
    "# creating the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'image_path' : image_paths,\n",
    "    'labels' : labels\n",
    "})\n",
    "\n",
    "# saving to a CSV\n",
    "csv_path = '/Path/to/your/EuroSAT_RGB.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Check the result\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also select only a few images from each subdirectory. This way the dataset is smaller and it will be faster to cluster it.\n",
    "\n",
    "# Initialize lists to store image paths and labels\n",
    "image_paths2 = []\n",
    "labels2 = []\n",
    "\n",
    "# Traverse the main folder\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    if subdir == root_dir:\n",
    "        continue  # Skip the main folder itself, we only want subfolders\n",
    "    \n",
    "    # Filter and collect image files (you can add more extensions if needed)\n",
    "    image_files = [f for f in files if f.lower().endswith(('.jpg'))]\n",
    "    \n",
    "    # Randomly select a number of images from the subfolder\n",
    "    n = 50\n",
    "    selected_images = random.sample(image_files, min(len(image_files), n))\n",
    "    \n",
    "    # Collect full paths and labels\n",
    "    for image in selected_images:\n",
    "        image_paths2.append(os.path.join(subdir, image))\n",
    "        labels2.append(os.path.basename(subdir))  # Label is the name of the subfolder\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    'image_path': image_paths2,\n",
    "    'label': labels2\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path2 = '/Path/to/your/EuroSAT_RGB_small.csv'\n",
    "df2.to_csv(csv_path2)\n",
    "\n",
    "# You can also check that the file is saved correctly and check the shape of it\n",
    "print(f\"CSV file saved to {csv_path2}\")\n",
    "print(df2.head())\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading the images and performing feature extraction with VGG16\n",
    "\n",
    "In this section we will read the images from our CSV file and use the pretrained VGG16 model from PyTorch, https://pytorch.org/vision/main/models/generated/torchvision.models.vgg16.html, to perform feature extraction from the images. VGG16 is a convolutional neural network that was developped by the Visual Geometry Group at the University of Oxford and it is widely used because of its simplicity. For example, in this example we can use the pretrained model to extract the features from the images rather quickly and easily. The features that it is collecting are for example edges, textures, patterns, shapes, and objects. By collecting these, the VGG16 model creates feature maps for each spatial location in the image and each position in the feature map represents how strongly a feature is present in that part of the image. After using this model we get an array that contains feature maps for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a list from Image objects\n",
    "all_image_objects = []\n",
    "\n",
    "# Iterating over the images in the DatafRame in batches\n",
    "def process_batch(image_paths):\n",
    "    image_objects = []\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            if os.path.exists(image_path):\n",
    "                with Image.open(image_path) as img:\n",
    "                    image_objects.append(img.copy())\n",
    "            else:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {image_path}: {e}\")\n",
    "    return image_objects\n",
    "    \n",
    "batch_size = 100 # This can be modified based on how many images you are iterating through\n",
    "for batch in pd.read_csv(csv_path, chunksize=batch_size):\n",
    "    image_paths = batch['image_path'].tolist()\n",
    "    batch_image_objects = process_batch(image_paths)\n",
    "    all_image_objects.extend(batch_image_objects)\n",
    "\n",
    "# Printing a few images to see that it works\n",
    "for img in all_image_objects[:5]:\n",
    "    print(img)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained model an its weights\n",
    "Vgg16 = models.vgg16(weights= models.VGG16_Weights.IMAGENET1K_FEATURES)\n",
    "Vgg16.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the preprocessing transformations, this is to have the images in the form so that the VGG16 accepts them\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Defining a function to do the feature extraction for each image\n",
    "def extract_features(image):\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = Vgg16.features(image)\n",
    "        features = features.view(features.size(0), -1)\n",
    "    return features.numpy()\n",
    "\n",
    "# Iterating through the image objects and saving the features into an array\n",
    "feature_list = []\n",
    "\n",
    "for image in all_image_objects:\n",
    "    features = extract_features(image)\n",
    "    feature_list.append(features[0])\n",
    "\n",
    "features_array = np.array(feature_list)\n",
    "\n",
    "# Checking that the array is correct\n",
    "print(features_array.shape)\n",
    "print(features_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Data Frame to save the features in \n",
    "df3 = pd.DataFrame(features_array)\n",
    "csv_path3 = '/Path/to/your/EuroSAT_RGB_Preprocessed.csv'\n",
    "df3.to_csv(csv_path3, index=False)\n",
    "\n",
    "# Check the result\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reducing the dimensions of the dataset with PCA\n",
    "\n",
    "To finish the preprocessing, PCA is used to reduce the dimesions of the feature array. PCA (principal component analysis) is an unsupervised machinle learning algorithm where the main goal is to reduce the dimensionality of the dataset while preserving the most important patterns and relations between the data points. This technique is used because the increase of dimensions can lead to overfitting, increased computation time, and reduced accuracy when performing different machine learning tasks.\n",
    "This for example applies to the k-means algorithm, thus we use PCA to make the clustering task easier. Also, in the quantum k-means the number of qubits needed increases based on the amount of features in the data. Thus, we want to have a simple dataset with only a few features so that the clustering can be performed with a few qubits too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the PCA from Scikit-learn to reduce the dimensions\n",
    "data = pd.read_csv(csv_path3)\n",
    "pca = PCA(n_components=2) # Choose the n_components based on how many features you want in your data\n",
    "pca.fit(data)\n",
    "features_reduced = pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the results of the feature reducing\n",
    "\n",
    "print(features_reduced.shape)\n",
    "print(features_reduced.dtype)\n",
    "print(pca.explained_variance_ratio_.cumsum()) # This tells us how much of the information is still left in the reduced data\n",
    "print(features_reduced[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the PCA can take a lot of time so the results can be saved into a CSV file\n",
    "# We also need to use this reduced data in the \"QKmeans\" notebook so it is good to have it saved\n",
    "pca_df = pd.DataFrame(features_reduced)\n",
    "pca_path = '/Path/to/your/EuroSAT_RGB_PCA.csv'\n",
    "pca_df.to_csv(pca_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data has been successfully prepared and preprocessed into a CSV file that is then easy to use for later computations. In the next Jupyter Notebook, we will use this data for the quantum and classical implementations of the K-means clustering algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
